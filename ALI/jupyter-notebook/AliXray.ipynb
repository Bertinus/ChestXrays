{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy import misc\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "from model import *\n",
    "from AliLoader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LS = 2 #Latent Space Size\n",
    "batch_size = 7\n",
    "ColorsNumber = 1\n",
    "\n",
    "#Encoder param\n",
    "EncKernel = [5,4,4,4,4,1,1]\n",
    "EncStride = [1,2,1,2,1,1,1]\n",
    "EncDepth = [32,64,128,256,512,512,LS]\n",
    "\n",
    "#Generator param\n",
    "GenKernel = [4,4,4,4,5,1,1]\n",
    "GenStride = [1,2,1,2,1,1,1]\n",
    "GenDepth = [256,128,64,32,32,32,ColorsNumber]\n",
    "\n",
    "#Discriminator X param\n",
    "DxKernel = [5,4,4,4,4]\n",
    "DxStride = [1,2,1,2,1]\n",
    "DxDepth = [32,64,128,256,512]\n",
    "\n",
    "#Discriminator Z param\n",
    "DzKernel = [1,1]\n",
    "DzStride = [1,1]\n",
    "DzDepth = [512,512]\n",
    "\n",
    "#Concat Discriminator param\n",
    "DxzKernel = [1,1,1]\n",
    "DxzStride = [1,1,1]\n",
    "DxzDepth = [1024,1024,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator param\n",
    "EncKernel = [2,7,5,7,4,1]\n",
    "EncStride = [1,2,2,2,1,1]\n",
    "EncDepth = [64,128,256,512,512,LS]\n",
    "\n",
    "#Generator param\n",
    "GenKernel = [4,7,5,7,2,1]\n",
    "GenStride = [1,2,2,2,1,1]\n",
    "GenDepth = [256,128,64,32,32,32,ColorsNumber]\n",
    "\n",
    "#Discriminator X param\n",
    "DxKernel = [2,7,5,7,4]\n",
    "DxStride = [1,2,2,2,1]\n",
    "DxDepth = [64,128,256,256,512]\n",
    "\n",
    "#Discriminator Z param\n",
    "DzKernel = [1,1]\n",
    "DzStride = [1,1]\n",
    "DzDepth = [512,512]\n",
    "\n",
    "#Concat Discriminator param\n",
    "DxzKernel = [1,1,1]\n",
    "DxzStride = [1,1,1]\n",
    "DxzDepth = [2048,2048,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"./images/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'DF'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f81e45d2d2e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Initialize dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXrayDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'DF'"
     ]
    }
   ],
   "source": [
    "# Transformations\n",
    "inputsize = [224, 224]\n",
    "inputsize = [32,32]\n",
    "inputsize = [64,64]\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(inputsize),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Lambda(lambda x: x.repeat(3, 1, 1))\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Initialize dataloader\n",
    "dataset = XrayDataset(datadir, transform=data_transforms)\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "ConstantImg = DataLoader(dataset, shuffle=False, batch_size=9)\n",
    "\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "    \n",
    "GenX = Generator(latent_size=LS,KS=GenKernel,ST=GenStride,DP=GenDepth)\n",
    "fkim = GenX(torch.rand(1,LS,1,1))\n",
    "print(fkim.shape)\n",
    "plt.imshow(fkim.detach().numpy()[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Maxout(nn.Module):\n",
    "    def __init__(self, pool_size):\n",
    "        super().__init__()\n",
    "        self._pool_size = pool_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.shape[-1] % self._pool_size == 0, \\\n",
    "            'Wrong input last dim size ({}) for Maxout({})'.format(x.shape[-1], self._pool_size)\n",
    "        m, i = x.view(*x.shape[:-1], x.shape[-1] // self._pool_size, self._pool_size).max(-1)\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(torch.randn(10000).detach().numpy(),bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7400, 0.9700, 0.7100, 0.7600, 0.8700, 1.0300, 1.0100, 0.9000, 1.0600,\n",
       "        0.7700, 1.0600, 1.0800, 0.7800, 1.0300, 0.9200, 0.8200, 0.7400, 1.0100,\n",
       "        0.8200, 0.9800, 0.9800, 0.8100, 0.8000, 0.8200, 0.8100, 1.0200, 1.0200,\n",
       "        0.7200, 1.0100, 0.7800, 0.7200, 0.9300, 1.0500, 0.8400, 0.7800, 1.0000,\n",
       "        0.8100, 0.7300, 0.9200, 0.7400, 0.8500, 0.7500, 1.0400, 0.7700, 0.7100,\n",
       "        0.7300, 1.0200, 0.7800, 0.8400, 0.7300, 1.0300, 0.8300, 0.8000, 1.0100,\n",
       "        0.8100, 0.9000, 0.9800, 1.0800, 0.9100, 0.9000, 0.9300, 0.9400, 0.8400,\n",
       "        0.8300, 0.8600, 0.7500, 0.7400, 1.0400, 1.0900, 0.7500, 0.9200, 1.0100,\n",
       "        0.8400, 1.0200, 0.9800, 0.8700, 0.7000, 0.9100, 1.0900, 1.0200, 0.9300,\n",
       "        0.8300, 1.0200, 0.7500, 0.7100, 0.7200, 0.8100, 0.8700, 0.7700, 1.0200,\n",
       "        1.0900, 1.0600, 1.0300, 0.7800, 0.8600, 1.0900, 0.8500, 1.0600, 1.0100,\n",
       "        0.8700, 1.0000, 0.7300, 0.7000, 0.9000, 1.0200, 1.0200, 1.0500, 0.8400,\n",
       "        0.8500, 0.8000, 0.9000, 0.7800, 0.8000, 1.0700, 0.8200, 1.0200, 1.0600,\n",
       "        0.8500, 1.0600, 0.7300, 1.0600, 0.7800, 1.0200, 0.7800, 0.9600, 0.9500,\n",
       "        1.0100, 0.7800, 0.9800, 0.7100, 0.9100, 0.8100, 1.0600, 0.7500, 0.9300,\n",
       "        1.0300, 1.0300, 0.8500, 0.9500, 0.8300, 0.8300, 0.9500, 0.8800, 1.0000,\n",
       "        1.0700, 0.7900, 0.7300, 0.7600, 1.0000, 0.9700, 0.7900, 0.9400, 1.0000,\n",
       "        0.9900, 1.0700, 0.7900, 0.8300, 0.8700, 1.0000, 0.8600, 0.7600, 0.9900,\n",
       "        1.0600, 0.9700, 0.9000, 1.0300, 0.7600, 0.9100, 0.9200, 1.0000, 0.7400,\n",
       "        0.8800, 1.0100, 0.9900, 0.8000, 0.7600, 1.0300, 0.8800, 0.8300, 1.0700,\n",
       "        0.7300, 0.8800, 0.7400, 0.9300, 0.7200, 0.9500, 0.8900, 1.0200, 0.9000,\n",
       "        0.7500, 0.9500, 0.9900, 0.7700, 0.7800, 0.8200, 0.8300, 0.9000, 0.8500,\n",
       "        0.8500, 0.8400, 0.9300, 0.7800, 1.0700, 0.8200, 1.0000, 0.8600, 1.0300,\n",
       "        0.7000, 0.9600, 0.9000, 0.9200, 1.0900, 0.8600, 1.0200, 0.8300, 0.9700,\n",
       "        0.7500, 1.0800, 1.0500, 0.8100, 0.8100, 1.0700, 1.0700, 1.0000, 0.9300,\n",
       "        0.9200, 0.9800, 0.7300, 0.9200, 0.7200, 0.7600, 0.7500, 0.9400, 1.0600,\n",
       "        0.9400, 0.7000, 0.8400, 0.8800, 0.9400, 0.8500, 0.7600, 0.8200, 0.8800,\n",
       "        0.8800, 0.8600, 0.7100, 0.7000, 0.7300, 0.8900, 0.8200, 0.8600, 0.8900,\n",
       "        0.9000, 0.9500, 0.9400, 0.9300, 1.0300, 0.7800, 0.8800, 0.8500, 0.9200,\n",
       "        0.8400, 0.8300, 0.9100, 1.0800, 0.9800, 0.8000, 1.0000, 1.0300, 0.9700,\n",
       "        0.8900, 0.9600, 0.9800, 0.9600, 1.0800, 1.0600, 0.8700, 0.9900, 0.9300,\n",
       "        0.9800, 1.0900, 0.7800, 1.0200, 0.8100, 0.8600, 0.7900, 0.8500, 1.0200,\n",
       "        0.8100, 1.0300, 0.9500, 0.9400, 1.0800, 0.9300, 0.9400, 0.8200, 1.0600,\n",
       "        0.9900, 1.0400, 0.9300, 0.8400, 0.7500, 0.8900, 0.7200, 0.7300, 0.7000,\n",
       "        0.7600, 0.8900, 0.8800, 0.9700, 0.7600, 0.7300, 1.0500, 0.9500, 0.8300,\n",
       "        0.7900, 0.8200, 0.7100, 0.7300, 1.0400, 0.8500, 0.7100, 0.8100, 1.0100,\n",
       "        1.0200, 0.8400, 1.0100, 0.9000, 0.7400, 1.0000, 1.0500, 0.7400, 0.8900,\n",
       "        0.8600, 0.9600, 1.0900, 1.0700, 0.8400, 0.7100, 0.8900, 0.7100, 1.0000,\n",
       "        0.9500, 0.8600, 0.9500, 0.7800, 0.8000, 0.8000, 1.0400, 1.0800, 0.8600,\n",
       "        0.8100, 1.0100, 0.9100, 0.8400, 0.7500, 0.9800, 1.0700, 0.9100, 0.8300,\n",
       "        0.8800, 0.8000, 0.8600, 0.9900, 0.9900, 1.0400, 0.9600, 0.9300, 0.9300,\n",
       "        0.7200, 0.9900, 1.0000, 0.9600, 1.0100, 1.0800, 0.7500, 0.7100, 0.8400,\n",
       "        1.0100, 1.0000, 0.9700, 1.0700, 0.8400, 0.8400, 0.7500, 1.0100, 1.0100,\n",
       "        1.0300, 0.8900, 0.9400, 1.0600, 0.9300, 0.7000, 1.0700, 1.0300, 0.9700,\n",
       "        0.8400, 0.8000, 0.7400, 0.7000, 0.9100, 0.7100, 0.9100, 0.7400, 0.7100,\n",
       "        0.8000, 0.9600, 0.7000, 0.8700, 0.9600, 0.9500, 1.0500, 0.9500, 0.8300,\n",
       "        0.7200, 1.0500, 0.8900, 1.0200, 1.0300, 0.9800, 1.0800, 0.9700, 0.8600,\n",
       "        0.9200, 0.7500, 0.9300, 0.8800, 0.9500, 0.8000, 0.7400, 0.9500, 1.0900,\n",
       "        0.9500, 1.0300, 0.7500, 1.0100, 0.8300, 0.7100, 0.8900, 0.9500, 0.9100,\n",
       "        0.8500, 0.7700, 0.7200, 0.9200, 0.7900, 0.8500, 1.0500, 0.7500, 1.0700,\n",
       "        0.9600, 0.9100, 0.8400, 1.0600, 0.7100, 0.8500, 0.9000, 1.0600, 0.9700,\n",
       "        0.8600, 1.0100, 0.9100, 0.9700, 0.9100, 0.7600, 0.7500, 0.8700, 1.0300,\n",
       "        1.0700, 0.8800, 0.9600, 1.0400, 0.7800, 0.7700, 0.9900, 1.0200, 0.9900,\n",
       "        1.0900, 1.0800, 0.8100, 1.0100, 0.7000, 1.0600, 0.7100, 1.0300, 1.0300,\n",
       "        0.9500, 0.9000, 0.9000, 1.0400, 0.7700, 1.0100, 1.0600, 0.8800, 0.8800,\n",
       "        0.9800, 0.9800, 0.9700, 0.7100, 0.7100, 0.7900, 1.0200, 0.7900, 1.0300,\n",
       "        0.8000, 0.7700, 0.8300, 1.0400, 0.7600, 0.9900, 1.0400, 0.8400, 1.0800,\n",
       "        1.0100, 0.9000, 1.0700, 1.0900, 0.8100, 0.7800, 1.0700, 0.9100, 1.0300,\n",
       "        0.8200, 1.0700, 0.8000, 0.9100, 0.8400, 0.8400, 1.0200, 0.7100, 0.7000,\n",
       "        0.8200, 0.9400, 0.8100, 0.8100, 0.9400, 0.7000, 0.9300, 1.0500, 1.0100,\n",
       "        1.0800, 0.9900, 0.9700, 0.9700, 0.7900, 0.9300, 0.7000, 1.0400, 0.7200,\n",
       "        0.9200, 0.7200, 0.9900, 0.9100, 0.8300, 0.9400, 1.0100, 0.7200, 0.9900,\n",
       "        1.0900, 0.7400, 0.8600, 0.7400, 0.7600, 0.9600, 0.7400, 0.7800, 1.0300,\n",
       "        1.0900, 1.0500, 0.9100, 0.9100, 1.0800, 0.7400, 0.7700, 1.0300, 1.0900,\n",
       "        1.0000, 0.9600, 0.7100, 1.0100, 0.8500, 1.0900, 1.0300, 0.7500, 1.0400,\n",
       "        1.0600, 0.7800, 1.0700, 0.8300, 0.7200, 1.0300, 1.0400, 0.8400, 0.9500,\n",
       "        0.8600, 1.0400, 0.7500, 0.7000, 1.0400, 0.8000, 0.8100, 1.0400, 0.7100,\n",
       "        1.0800, 0.8700, 0.7800, 0.7900, 0.7100, 0.9200, 1.0400, 0.8400, 0.8500,\n",
       "        0.8700, 0.9900, 1.0700, 0.8900, 1.0900, 0.9800, 0.9700, 0.9700, 1.0000,\n",
       "        1.0800, 0.9500, 0.7800, 0.8300, 0.7900, 1.0700, 0.8500, 0.8500, 0.9200,\n",
       "        1.0300, 0.9800, 0.7000, 0.8700, 0.9500, 0.9900, 1.0200, 1.0200, 0.8300,\n",
       "        0.7000, 1.0200, 0.8000, 0.9600, 0.9300, 0.9000, 1.0900, 0.7200, 0.8600,\n",
       "        0.8400, 0.8000, 0.9400, 0.9900, 0.9300, 1.0600, 0.9000, 0.8800, 0.9400,\n",
       "        1.0000, 1.0600, 0.7400, 0.7300, 0.9500, 0.7200, 0.8000, 0.8100, 0.7700,\n",
       "        1.0800, 1.0600, 0.8900, 0.9800, 0.9100, 0.8000, 0.8900, 1.0900, 0.9800,\n",
       "        0.8100, 0.8000, 0.9000, 0.7000, 0.9800, 0.9700, 1.0500, 0.8700, 0.9600,\n",
       "        0.7100, 0.9000, 0.7100, 0.7900, 0.9100, 1.0700, 1.0900, 1.0300, 1.0400,\n",
       "        1.0500, 0.8500, 1.0400, 0.8200, 1.0800, 0.8300, 0.7200, 0.8100, 1.0800,\n",
       "        0.7300, 0.9900, 0.8500, 0.8100, 0.9800, 1.0200, 0.8700, 0.8000, 1.0900,\n",
       "        0.7500, 0.9800, 0.8800, 0.8000, 1.0600, 0.7600, 0.9800, 0.9000, 0.7100,\n",
       "        1.0900, 1.0200, 0.9200, 0.7600, 0.7400, 1.0600, 0.8900, 1.0600, 0.8400,\n",
       "        0.7100, 0.8800, 0.9000, 0.7200, 0.9700, 0.7300, 0.8500, 0.7300, 0.8900,\n",
       "        0.7700, 1.0400, 0.7000, 0.8700, 0.9900, 0.9600, 0.7300, 0.7700, 0.8400,\n",
       "        0.7400, 0.7900, 0.8100, 0.9800, 1.0000, 0.8600, 0.8600, 1.0900, 0.9900,\n",
       "        0.9400, 1.0200, 0.9200, 0.7600, 0.8300, 0.8100, 0.8300, 0.8500, 0.8800,\n",
       "        0.7900, 1.0600, 0.7600, 0.8900, 1.0900, 0.8000, 0.7500, 0.8900, 0.7700,\n",
       "        1.0900, 0.7000, 0.8300, 1.0300, 0.8700, 1.0000, 0.8100, 0.8800, 0.7200,\n",
       "        0.7200, 0.9900, 0.7200, 1.0700, 0.7300, 0.7800, 1.0700, 0.9800, 0.7700,\n",
       "        1.0200, 0.7900, 0.7500, 0.9500, 0.7800, 0.8400, 0.8900, 0.8400, 1.0600,\n",
       "        0.9900, 0.7600, 0.7300, 0.9300, 0.9000, 0.8700, 0.8500, 0.9500, 0.7200,\n",
       "        0.9400, 0.9200, 0.8900, 1.0800, 0.8300, 1.0100, 0.7000, 0.9800, 0.7000,\n",
       "        0.9000, 0.9500, 0.7900, 0.8500, 0.7600, 0.7500, 0.8400, 0.7100, 1.0200,\n",
       "        0.8400, 1.0900, 0.7800, 1.0500, 0.9700, 0.7800, 1.0500, 0.8700, 0.9300,\n",
       "        0.8700, 0.8400, 0.7800, 1.0400, 0.7800, 0.9400, 1.0100, 0.9000, 0.9700,\n",
       "        0.8700, 0.9600, 0.7400, 0.9800, 0.9300, 0.8100, 1.0200, 0.7500, 0.8500,\n",
       "        1.0800, 0.9700, 0.9600, 0.7600, 0.9500, 1.0500, 1.0600, 0.8700, 0.9100,\n",
       "        0.8200, 1.0100, 1.0200, 0.7700, 1.0800, 0.9200, 0.7400, 1.0700, 1.0100,\n",
       "        1.0700, 0.7200, 1.0500, 0.8800, 0.8300, 0.8000, 0.7400, 1.0400, 0.7800,\n",
       "        0.9200, 0.8900, 0.7200, 0.8400, 0.9600, 0.9900, 0.8900, 1.0200, 0.7700,\n",
       "        0.9500, 0.7500, 0.9300, 0.8200, 0.7200, 1.0500, 1.0700, 0.8000, 0.9500,\n",
       "        0.8400, 0.7100, 0.9900, 0.8700, 1.0000, 0.7400, 0.9800, 0.7700, 0.8500,\n",
       "        1.0700, 0.7700, 0.7200, 1.0600, 0.8400, 0.7000, 0.8200, 0.8800, 0.7600,\n",
       "        0.8800, 0.7900, 0.7100, 0.9200, 0.8800, 1.0300, 0.9600, 1.0300, 0.7900,\n",
       "        1.0300, 0.8400, 1.0500, 0.9500, 0.8800, 1.0900, 0.8000, 1.0800, 0.8500,\n",
       "        0.9200, 1.0000, 1.0300, 0.8300, 1.0400, 0.8100, 1.0200, 1.0300, 1.0800,\n",
       "        0.7700, 1.0000, 0.9400, 0.9100, 1.0700, 1.0600, 0.7200, 0.7800, 0.8500,\n",
       "        0.8500, 0.7800, 0.7800, 0.7100, 0.8400, 0.9300, 1.0900, 1.0300, 0.9800,\n",
       "        1.0800, 0.8900, 0.9100, 0.9300, 0.9900, 0.8500, 0.9900, 0.7200, 1.0300,\n",
       "        0.9100, 1.0800, 0.7300, 0.8400, 0.9400, 0.8800, 0.9600, 1.0500, 0.7600,\n",
       "        0.7500, 0.9400, 0.9900, 0.9300, 1.0900, 0.9000, 0.9600, 0.7600, 0.9400,\n",
       "        0.8600, 1.0100, 0.9900, 0.8300, 1.0800, 0.9000, 0.9900, 1.0300, 0.7100,\n",
       "        0.8600])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist((torch.randint(low=70, high=110, size=(1,1000))[0] / 100).detach().numpy(),bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DisX = DiscriminatorX(KS=DxKernel,ST=DxStride,DP=DxDepth)\n",
    "DisZ = DiscriminatorZ(KS=DzKernel,ST=DzStride,DP=DzDepth,LS=LS)\n",
    "DisXZ = DiscriminatorXZ(KS=DxzKernel,ST=DxzStride,DP=DxzDepth)\n",
    "\n",
    "GenZ = Encoder(KS=EncKernel,ST=EncStride,DP=EncDepth,LS=LS)\n",
    "GenX = Generator(latent_size=LS,KS=GenKernel,ST=GenStride,DP=GenDepth)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataiter in ConstantImg:\n",
    "    #Get Data\n",
    "    data = dataiter\n",
    "    data_norm = data*2.0-1.0\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lr = 1e-4\n",
    "b1 = 0.5\n",
    "b2 = 1e-3\n",
    "optimizerG = optim.Adam([{'params' : GenX.parameters()},\n",
    "                         {'params' : GenZ.parameters()}], lr=lr, betas=(b1,b2))\n",
    "\n",
    "optimizerD = optim.Adam([{'params' : DisZ.parameters()},{'params': DisX.parameters()},\n",
    "                         {'params' : DisXZ.parameters()}], lr=lr, betas=(b1,b2))\n",
    "\n",
    "DiscriminatorLoss = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "ConstantZ = torch.randn(9,LS,1,1)\n",
    "\n",
    "cpt = 0\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "for epoch in range(2):\n",
    "    \n",
    "    #Store Discriminator data\n",
    "    AllRealDisc = []\n",
    "    AllFakeDisc = []\n",
    "    \n",
    "    \n",
    "    c = 0\n",
    "    for dataiter in dataloader:\n",
    "        c += 1\n",
    "        \n",
    "        #Get Data\n",
    "        Xnorm = dataiter *2.0 - 1.0\n",
    "        #print(c,Xnorm.shape)\n",
    "        #To cuda\n",
    "        if torch.cuda.is_available():\n",
    "            Xnorm = Xnorm.cuda()\n",
    "        \n",
    "        #Get Batch Size\n",
    "        BS = Xnorm.shape[0]\n",
    "        if BS < batch_size/2.0:\n",
    "            continue\n",
    "        \n",
    "        #Generate Fake data from random Latent\n",
    "        FakeZ = torch.randn(BS,LS,1,1)\n",
    "        FakeX = GenX(FakeZ)\n",
    "        #print(\"FakeZ\",FakeZ.shape)\n",
    "        #print(\"FakeX\",FakeX.shape)\n",
    "        #Generate Latent from Real\n",
    "        RealZ = GenZ(Xnorm)\n",
    "        #print(\"RealZ\",RealZ.shape)\n",
    "        #Have discriminator do is thing on real and fake data\n",
    "        print(DisZ(RealZ).shape)\n",
    "        RealCat= torch.cat((DisZ(RealZ), DisX(Xnorm)), 1)\n",
    "        FakeCat= torch.cat((DisZ(FakeZ), DisX(FakeX)), 1)\n",
    "        #print(RealCat.shape)\n",
    "        \n",
    "        PredReal  = DisXZ(RealCat)\n",
    "        PredFalse = DisXZ(FakeCat)\n",
    "        \n",
    "        #Get loss for discriminator\n",
    "        loss_d = criterion(PredReal.view(-1), Variable(torch.ones(BS)-0.1)) + criterion(PredFalse.view(-1), Variable(torch.zeros(BS)))\n",
    "\n",
    "        #Get loss for generator\n",
    "        loss_g = criterion(PredFalse.view(-1), Variable(torch.ones(BS)-0.1)) + criterion(PredReal.view(-1), Variable(torch.zeros(BS)))\n",
    "\n",
    "        #Optimize Discriminator\n",
    "        \n",
    "        optimizerD.zero_grad()\n",
    "        loss_d.backward(retain_graph=True)\n",
    "        optimizerD.step()\n",
    "    \n",
    "        #Optimize Generator\n",
    "        \n",
    "        optimizerG.zero_grad()\n",
    "        loss_g.backward()\n",
    "        optimizerG.step()\n",
    "    \n",
    "    \n",
    "        #StoreInfo\n",
    "        DiscriminatorLoss.append(loss_d.detach().numpy()+0)\n",
    "        AllRealDisc = list(np.ravel(PredReal.detach().numpy()))\n",
    "        AllFakeDisc = list(np.ravel(PredFalse.detach().numpy()))\n",
    "        \n",
    "        break\n",
    "        \n",
    "    if epoch % 1 == 0:\n",
    "        with torch.no_grad():\n",
    "            FakeData = GenX(ConstantZ).detach().numpy()\n",
    "            plt.imshow(FakeData[0][0])\n",
    "            plt.title(\"Epoch %d\" % (epoch))\n",
    "            plt.show()\n",
    "\n",
    "            plt.imshow(data[0][0])\n",
    "            plt.title(\"Epoch %d\" % (epoch))\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            #print(\"Epoch:%d AUC:%.2f\" % (epoch,auc))\n",
    "\n",
    "            plt.hist(AllRealDisc,bins=np.array(range(20))/20,label=\"Real\")\n",
    "            plt.hist(AllFakeDisc,np.array(range(20))/20,label=\"False\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            plt.plot(range(len(DiscriminatorLoss)),DiscriminatorLoss)\n",
    "            plt.show()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    FakeData = GenX(ConstantZ)\n",
    "\n",
    "    PredFalse = DisXZ(torch.cat((DisZ(ConstantZ), DisX(FakeData)), 1))\n",
    "\n",
    "\n",
    "    FakeData = FakeData.detach().numpy()\n",
    "    PredFalse= PredFalse.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "c = 0\n",
    "for i in range(9):\n",
    "    c +=1\n",
    "    #print(fd.shape)\n",
    "    plt.subplot(3,3,c)\n",
    "    plt.imshow(FakeData[i][0],cmap=\"gray\")\n",
    "    plt.title(\"Disc=%.2f\" % (PredFalse[i]))\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Get the colormap colors\n",
    "cmap = plt.cm.Reds\n",
    "AlphaRed = cmap(np.arange(cmap.N))\n",
    "# Set alpha\n",
    "AlphaRed[:,-1] = np.linspace(0, 1, cmap.N)\n",
    "# Create new colormap\n",
    "AlphaRed = ListedColormap(AlphaRed)\n",
    "AllX = []\n",
    "for dataiter in ConstantImg:\n",
    "    #Get Data\n",
    "    data = dataiter\n",
    "    Xnorm = data*2.0-1.0\n",
    "    AllX += list(Xnorm.detach().numpy())\n",
    "    break\n",
    "with torch.no_grad():\n",
    "    #Generate Latent from Real\n",
    "    RealZ = GenZ(Xnorm)\n",
    "    RebuildX = GenX(RealZ)\n",
    "    DiffX = Xnorm - RebuildX\n",
    "    DiffX = DiffX.detach().numpy()\n",
    "    DiffX = np.power(DiffX,2)\n",
    "    RebuildX = RebuildX.detach().numpy()\n",
    "    #Have discriminator do is thing on real and fake data\n",
    "    PredReal  = DisXZ(torch.cat((DisZ(RealZ), DisX(Xnorm)), 1)).detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "c = 0\n",
    "Sample = 3\n",
    "\n",
    "for i in range(Sample):\n",
    "    c+= 1\n",
    "    plt.subplot(Sample,3,c)\n",
    "    plt.imshow(Xnorm[i][0],cmap=\"gray\")\n",
    "    plt.title(\"Init Disc=%.2f\" % (PredReal[i]))\n",
    "    plt.axis(\"off\")\n",
    "    c+= 1\n",
    "    plt.subplot(Sample,3,c)\n",
    "    plt.imshow(RebuildX[i][0],cmap=\"gray\")\n",
    "    plt.title(\"Reconstruct\")\n",
    "    plt.axis(\"off\")\n",
    "    c+= 1\n",
    "    plt.subplot(Sample,3,c)\n",
    "    plt.imshow(Xnorm[i][0],cmap=\"gray\")\n",
    "    plt.title(\"Rec Error = %.2f\" % (np.mean(DiffX[i][0])))\n",
    "    plt.imshow(DiffX[i][0],cmap=AlphaRed,vmin=0,vmax=2)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    \n",
    "    \n",
    "plt.savefig(\"./test.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnorm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Xnorm.detach().numpy()[0][0])\n",
    "plt.show()\n",
    "XFlip = np.copy(Xnorm.detach().numpy())\n",
    "XFlip = XFlip[:,:,range(32)[::-1],:]\n",
    "\n",
    "XFlip = torch.tensor(XFlip)\n",
    "print(XFlip.shape)\n",
    "plt.imshow(XFlip.detach().numpy()[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = RealZ.detach().numpy()\n",
    "Z.resize((RealZ.shape[:2]))\n",
    "print(np.sum(np.power(Z,2),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Xnorm.detach().numpy()[0][0])\n",
    "plt.show()\n",
    "\n",
    "XnormShuffle = np.copy(Xnorm.reshape(9,64*64).detach().numpy())\n",
    "print(XnormShuffle.shape)\n",
    "print(np.mean(XnormShuffle,axis=1))\n",
    "np.random.shuffle(XnormShuffle.transpose())\n",
    "print(np.mean(XnormShuffle,axis=1))\n",
    "print(XnormShuffle.shape)\n",
    "XnormShuffle = torch.tensor(XnormShuffle)\n",
    "\n",
    "XnormShuffle = XnormShuffle.reshape(9,1,32,32)\n",
    "plt.imshow(XnormShuffle.detach().numpy()[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.ToPILImage(),\n",
    "    transforms.Resize(inputsize),\n",
    "    transforms.ToTensor(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnorm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load MNIST\n",
    "#MNIST\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                    transforms.Resize([64,64]),\n",
    "                    transforms.ToTensor()])\n",
    "\n",
    "MNIST_set = dset.MNIST(root=\"./model/default/\", train=True, transform=transform, download=True)\n",
    "MNIST_loader = torch.utils.data.DataLoader(dataset=MNIST_set,batch_size=9,shuffle=False)\n",
    "\n",
    "for mnist,lab in MNIST_loader:\n",
    "    print(mnist.shape)\n",
    "    plt.imshow(mnist[0][0])\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FakeData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mnist[0][0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "Xr = RealZ.detach().numpy()\n",
    "Xr.resize((Xr.shape[:2]))\n",
    "\n",
    "\n",
    "Xf = ConstantZ.detach().numpy()\n",
    "Xf.resize((Xf.shape[:2]))\n",
    "\n",
    "X = np.concatenate((Xf,Xr))\n",
    "\n",
    "tsne = manifold.TSNE(n_components=2, init='random',\n",
    "                     random_state=0, perplexity=5)\n",
    "Y = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y[:Xr.shape[0],0],Y[:Xr.shape[0],1],c=\"red\")\n",
    "plt.scatter(Y[Xr.shape[0]:,0],Y[Xr.shape[0]:,1],c=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Xr[:,0],Xr[:,1],c=\"red\")\n",
    "plt.scatter(Xf[:,0],Xf[:,1],c=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OtherXrayDataset(Dataset):\n",
    "\n",
    "    def __init__(self, datadir, transform=None, nrows=-1):\n",
    "\n",
    "        self.datadir = datadir\n",
    "        self.transform = transform\n",
    "        print(datadir+\"/*/*/*.png\")\n",
    "        self.ImgFiles = [f.split(datadir)[-1] for f in glob.glob(datadir+\"/*/*/*/*.png\")]\n",
    "        if nrows > 0:\n",
    "            self.ImgFiles = self.ImgFiles[:nrows]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ImgFiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #print(idx)\n",
    "        #print(self.datadir)\n",
    "        print(idx,os.path.join(self.datadir, self.ImgFiles[idx]))\n",
    "        im = misc.imread(os.path.join(self.datadir, self.ImgFiles[idx]))\n",
    "        print(im.shape)\n",
    "        if len(im.shape) > 2:\n",
    "            im = im[:, :, 0]\n",
    "        #Add color chanel\n",
    "        im = im[:,:,None]\n",
    "        # Tranform\n",
    "        if self.transform:\n",
    "            im = self.transform(im)\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OtherXRay = OtherXrayDataset(\"./OtherXray/\", transform=data_transforms,nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OtherXRay = OtherXrayDataset(\"./OtherXray/\", transform=data_transforms)\n",
    "otherxray = DataLoader(OtherXRay, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = misc.imread(\"./OtherXray/XR_FINGER/patient04136/study1_negative/image1.png\")\n",
    "print(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for oxray in otherxray:\n",
    "    XNROM = oxray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:xray]",
   "language": "python",
   "name": "conda-env-xray-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
