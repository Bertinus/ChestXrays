{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy import misc\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "from model import *\n",
    "from AliLoader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LS = 2 #Latent Space Size\n",
    "batch_size = 7\n",
    "ColorsNumber = 1\n",
    "\n",
    "#Encoder param\n",
    "EncKernel = [5,4,4,4,4,1,1]\n",
    "EncStride = [1,2,1,2,1,1,1]\n",
    "EncDepth = [32,64,128,256,512,512,LS]\n",
    "\n",
    "#Generator param\n",
    "GenKernel = [4,4,4,4,5,1,1]\n",
    "GenStride = [1,2,1,2,1,1,1]\n",
    "GenDepth = [256,128,64,32,32,32,ColorsNumber]\n",
    "\n",
    "#Discriminator X param\n",
    "DxKernel = [5,4,4,4,4]\n",
    "DxStride = [1,2,1,2,1]\n",
    "DxDepth = [32,64,128,256,512]\n",
    "\n",
    "#Discriminator Z param\n",
    "DzKernel = [1,1]\n",
    "DzStride = [1,1]\n",
    "DzDepth = [512,512]\n",
    "\n",
    "#Concat Discriminator param\n",
    "DxzKernel = [1,1,1]\n",
    "DxzStride = [1,1,1]\n",
    "DxzDepth = [1024,1024,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator param\n",
    "EncKernel = [2,7,5,7,4,1]\n",
    "EncStride = [1,2,2,2,1,1]\n",
    "EncDepth = [64,128,256,512,512,LS]\n",
    "\n",
    "#Generator param\n",
    "GenKernel = [4,7,5,7,2,1]\n",
    "GenStride = [1,2,2,2,1,1]\n",
    "GenDepth = [256,128,64,32,32,32,ColorsNumber]\n",
    "\n",
    "#Discriminator X param\n",
    "DxKernel = [2,7,5,7,4]\n",
    "DxStride = [1,2,2,2,1]\n",
    "DxDepth = [64,128,256,256,512]\n",
    "\n",
    "#Discriminator Z param\n",
    "DzKernel = [1,1]\n",
    "DzStride = [1,1]\n",
    "DzDepth = [512,512]\n",
    "\n",
    "#Concat Discriminator param\n",
    "DxzKernel = [1,1,1]\n",
    "DxzStride = [1,1,1]\n",
    "DxzDepth = [2048,2048,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"./images/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "inputsize = [224, 224]\n",
    "inputsize = [32,32]\n",
    "inputsize = [64,64]\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(inputsize),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Lambda(lambda x: x.repeat(3, 1, 1))\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Initialize dataloader\n",
    "dataset = XrayDataset(datadir, transform=data_transforms)\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "ConstantImg = DataLoader(dataset, shuffle=False, batch_size=9)\n",
    "\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "    \n",
    "GenX = Generator(latent_size=LS,KS=GenKernel,ST=GenStride,DP=GenDepth)\n",
    "fkim = GenX(torch.rand(1,LS,1,1))\n",
    "print(fkim.shape)\n",
    "plt.imshow(fkim.detach().numpy()[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Maxout(nn.Module):\n",
    "    def __init__(self, pool_size):\n",
    "        super().__init__()\n",
    "        self._pool_size = pool_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.shape[-1] % self._pool_size == 0, \\\n",
    "            'Wrong input last dim size ({}) for Maxout({})'.format(x.shape[-1], self._pool_size)\n",
    "        m, i = x.view(*x.shape[:-1], x.shape[-1] // self._pool_size, self._pool_size).max(-1)\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DisX = DiscriminatorX(KS=DxKernel,ST=DxStride,DP=DxDepth)\n",
    "DisZ = DiscriminatorZ(KS=DzKernel,ST=DzStride,DP=DzDepth,LS=LS)\n",
    "DisXZ = DiscriminatorXZ(KS=DxzKernel,ST=DxzStride,DP=DxzDepth)\n",
    "\n",
    "GenZ = Encoder(KS=EncKernel,ST=EncStride,DP=EncDepth,LS=LS)\n",
    "GenX = Generator(latent_size=LS,KS=GenKernel,ST=GenStride,DP=GenDepth)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataiter in ConstantImg:\n",
    "    #Get Data\n",
    "    data = dataiter\n",
    "    data_norm = data*2.0-1.0\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lr = 1e-4\n",
    "b1 = 0.5\n",
    "b2 = 1e-3\n",
    "optimizerG = optim.Adam([{'params' : GenX.parameters()},\n",
    "                         {'params' : GenZ.parameters()}], lr=lr, betas=(b1,b2))\n",
    "\n",
    "optimizerD = optim.Adam([{'params' : DisZ.parameters()},{'params': DisX.parameters()},\n",
    "                         {'params' : DisXZ.parameters()}], lr=lr, betas=(b1,b2))\n",
    "\n",
    "DiscriminatorLoss = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "ConstantZ = torch.randn(9,LS,1,1)\n",
    "\n",
    "cpt = 0\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "for epoch in range(2):\n",
    "    \n",
    "    #Store Discriminator data\n",
    "    AllRealDisc = []\n",
    "    AllFakeDisc = []\n",
    "    \n",
    "    \n",
    "    c = 0\n",
    "    for dataiter in dataloader:\n",
    "        c += 1\n",
    "        \n",
    "        #Get Data\n",
    "        Xnorm = dataiter *2.0 - 1.0\n",
    "        #print(c,Xnorm.shape)\n",
    "        #To cuda\n",
    "        if torch.cuda.is_available():\n",
    "            Xnorm = Xnorm.cuda()\n",
    "        \n",
    "        #Get Batch Size\n",
    "        BS = Xnorm.shape[0]\n",
    "        if BS < batch_size/2.0:\n",
    "            continue\n",
    "        \n",
    "        #Generate Fake data from random Latent\n",
    "        FakeZ = torch.randn(BS,LS,1,1)\n",
    "        FakeX = GenX(FakeZ)\n",
    "        #print(\"FakeZ\",FakeZ.shape)\n",
    "        #print(\"FakeX\",FakeX.shape)\n",
    "        #Generate Latent from Real\n",
    "        RealZ = GenZ(Xnorm)\n",
    "        #print(\"RealZ\",RealZ.shape)\n",
    "        #Have discriminator do is thing on real and fake data\n",
    "        print(DisZ(RealZ).shape)\n",
    "        RealCat= torch.cat((DisZ(RealZ), DisX(Xnorm)), 1)\n",
    "        FakeCat= torch.cat((DisZ(FakeZ), DisX(FakeX)), 1)\n",
    "        #print(RealCat.shape)\n",
    "        \n",
    "        PredReal  = DisXZ(RealCat)\n",
    "        PredFalse = DisXZ(FakeCat)\n",
    "        \n",
    "        #Get loss for discriminator\n",
    "        loss_d = criterion(PredReal.view(-1), Variable(torch.ones(BS)-0.1)) + criterion(PredFalse.view(-1), Variable(torch.zeros(BS)))\n",
    "\n",
    "        #Get loss for generator\n",
    "        loss_g = criterion(PredFalse.view(-1), Variable(torch.ones(BS)-0.1)) + criterion(PredReal.view(-1), Variable(torch.zeros(BS)))\n",
    "\n",
    "        #Optimize Discriminator\n",
    "        \n",
    "        optimizerD.zero_grad()\n",
    "        loss_d.backward(retain_graph=True)\n",
    "        optimizerD.step()\n",
    "    \n",
    "        #Optimize Generator\n",
    "        \n",
    "        optimizerG.zero_grad()\n",
    "        loss_g.backward()\n",
    "        optimizerG.step()\n",
    "    \n",
    "    \n",
    "        #StoreInfo\n",
    "        DiscriminatorLoss.append(loss_d.detach().numpy()+0)\n",
    "        AllRealDisc = list(np.ravel(PredReal.detach().numpy()))\n",
    "        AllFakeDisc = list(np.ravel(PredFalse.detach().numpy()))\n",
    "        \n",
    "        break\n",
    "        \n",
    "    if epoch % 1 == 0:\n",
    "        with torch.no_grad():\n",
    "            FakeData = GenX(ConstantZ).detach().numpy()\n",
    "            plt.imshow(FakeData[0][0])\n",
    "            plt.title(\"Epoch %d\" % (epoch))\n",
    "            plt.show()\n",
    "\n",
    "            plt.imshow(data[0][0])\n",
    "            plt.title(\"Epoch %d\" % (epoch))\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            #print(\"Epoch:%d AUC:%.2f\" % (epoch,auc))\n",
    "\n",
    "            plt.hist(AllRealDisc,bins=np.array(range(20))/20,label=\"Real\")\n",
    "            plt.hist(AllFakeDisc,np.array(range(20))/20,label=\"False\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            plt.plot(range(len(DiscriminatorLoss)),DiscriminatorLoss)\n",
    "            plt.show()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    FakeData = GenX(ConstantZ)\n",
    "\n",
    "    PredFalse = DisXZ(torch.cat((DisZ(ConstantZ), DisX(FakeData)), 1))\n",
    "\n",
    "\n",
    "    FakeData = FakeData.detach().numpy()\n",
    "    PredFalse= PredFalse.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "c = 0\n",
    "for i in range(9):\n",
    "    c +=1\n",
    "    #print(fd.shape)\n",
    "    plt.subplot(3,3,c)\n",
    "    plt.imshow(FakeData[i][0],cmap=\"gray\")\n",
    "    plt.title(\"Disc=%.2f\" % (PredFalse[i]))\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Get the colormap colors\n",
    "cmap = plt.cm.Reds\n",
    "AlphaRed = cmap(np.arange(cmap.N))\n",
    "# Set alpha\n",
    "AlphaRed[:,-1] = np.linspace(0, 1, cmap.N)\n",
    "# Create new colormap\n",
    "AlphaRed = ListedColormap(AlphaRed)\n",
    "AllX = []\n",
    "for dataiter in ConstantImg:\n",
    "    #Get Data\n",
    "    data = dataiter\n",
    "    Xnorm = data*2.0-1.0\n",
    "    AllX += list(Xnorm.detach().numpy())\n",
    "    break\n",
    "with torch.no_grad():\n",
    "    #Generate Latent from Real\n",
    "    RealZ = GenZ(Xnorm)\n",
    "    RebuildX = GenX(RealZ)\n",
    "    DiffX = Xnorm - RebuildX\n",
    "    DiffX = DiffX.detach().numpy()\n",
    "    DiffX = np.power(DiffX,2)\n",
    "    RebuildX = RebuildX.detach().numpy()\n",
    "    #Have discriminator do is thing on real and fake data\n",
    "    PredReal  = DisXZ(torch.cat((DisZ(RealZ), DisX(Xnorm)), 1)).detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "c = 0\n",
    "Sample = 3\n",
    "\n",
    "for i in range(Sample):\n",
    "    c+= 1\n",
    "    plt.subplot(Sample,3,c)\n",
    "    plt.imshow(Xnorm[i][0],cmap=\"gray\")\n",
    "    plt.title(\"Init Disc=%.2f\" % (PredReal[i]))\n",
    "    plt.axis(\"off\")\n",
    "    c+= 1\n",
    "    plt.subplot(Sample,3,c)\n",
    "    plt.imshow(RebuildX[i][0],cmap=\"gray\")\n",
    "    plt.title(\"Reconstruct\")\n",
    "    plt.axis(\"off\")\n",
    "    c+= 1\n",
    "    plt.subplot(Sample,3,c)\n",
    "    plt.imshow(Xnorm[i][0],cmap=\"gray\")\n",
    "    plt.title(\"Rec Error = %.2f\" % (np.mean(DiffX[i][0])))\n",
    "    plt.imshow(DiffX[i][0],cmap=AlphaRed,vmin=0,vmax=2)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    \n",
    "    \n",
    "plt.savefig(\"./test.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnorm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Xnorm.detach().numpy()[0][0])\n",
    "plt.show()\n",
    "XFlip = np.copy(Xnorm.detach().numpy())\n",
    "XFlip = XFlip[:,:,range(32)[::-1],:]\n",
    "\n",
    "XFlip = torch.tensor(XFlip)\n",
    "print(XFlip.shape)\n",
    "plt.imshow(XFlip.detach().numpy()[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = RealZ.detach().numpy()\n",
    "Z.resize((RealZ.shape[:2]))\n",
    "print(np.sum(np.power(Z,2),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Xnorm.detach().numpy()[0][0])\n",
    "plt.show()\n",
    "\n",
    "XnormShuffle = np.copy(Xnorm.reshape(9,64*64).detach().numpy())\n",
    "print(XnormShuffle.shape)\n",
    "print(np.mean(XnormShuffle,axis=1))\n",
    "np.random.shuffle(XnormShuffle.transpose())\n",
    "print(np.mean(XnormShuffle,axis=1))\n",
    "print(XnormShuffle.shape)\n",
    "XnormShuffle = torch.tensor(XnormShuffle)\n",
    "\n",
    "XnormShuffle = XnormShuffle.reshape(9,1,32,32)\n",
    "plt.imshow(XnormShuffle.detach().numpy()[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.ToPILImage(),\n",
    "    transforms.Resize(inputsize),\n",
    "    transforms.ToTensor(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnorm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load MNIST\n",
    "#MNIST\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                    transforms.Resize([64,64]),\n",
    "                    transforms.ToTensor()])\n",
    "\n",
    "MNIST_set = dset.MNIST(root=\"./model/default/\", train=True, transform=transform, download=True)\n",
    "MNIST_loader = torch.utils.data.DataLoader(dataset=MNIST_set,batch_size=9,shuffle=False)\n",
    "\n",
    "for mnist,lab in MNIST_loader:\n",
    "    print(mnist.shape)\n",
    "    plt.imshow(mnist[0][0])\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FakeData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mnist[0][0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "Xr = RealZ.detach().numpy()\n",
    "Xr.resize((Xr.shape[:2]))\n",
    "\n",
    "\n",
    "Xf = ConstantZ.detach().numpy()\n",
    "Xf.resize((Xf.shape[:2]))\n",
    "\n",
    "X = np.concatenate((Xf,Xr))\n",
    "\n",
    "tsne = manifold.TSNE(n_components=2, init='random',\n",
    "                     random_state=0, perplexity=5)\n",
    "Y = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y[:Xr.shape[0],0],Y[:Xr.shape[0],1],c=\"red\")\n",
    "plt.scatter(Y[Xr.shape[0]:,0],Y[Xr.shape[0]:,1],c=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Xr[:,0],Xr[:,1],c=\"red\")\n",
    "plt.scatter(Xf[:,0],Xf[:,1],c=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OtherXrayDataset(Dataset):\n",
    "\n",
    "    def __init__(self, datadir, transform=None, nrows=-1):\n",
    "\n",
    "        self.datadir = datadir\n",
    "        self.transform = transform\n",
    "        print(datadir+\"/*/*/*.png\")\n",
    "        self.ImgFiles = [f.split(datadir)[-1] for f in glob.glob(datadir+\"/*/*/*/*.png\")]\n",
    "        if nrows > 0:\n",
    "            self.ImgFiles = self.ImgFiles[:nrows]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ImgFiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #print(idx)\n",
    "        #print(self.datadir)\n",
    "        print(idx,os.path.join(self.datadir, self.ImgFiles[idx]))\n",
    "        im = misc.imread(os.path.join(self.datadir, self.ImgFiles[idx]))\n",
    "        print(im.shape)\n",
    "        if len(im.shape) > 2:\n",
    "            im = im[:, :, 0]\n",
    "        #Add color chanel\n",
    "        im = im[:,:,None]\n",
    "        # Tranform\n",
    "        if self.transform:\n",
    "            im = self.transform(im)\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OtherXRay = OtherXrayDataset(\"./OtherXray/\", transform=data_transforms,nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OtherXRay = OtherXrayDataset(\"./OtherXray/\", transform=data_transforms)\n",
    "otherxray = DataLoader(OtherXRay, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = misc.imread(\"./OtherXray/XR_FINGER/patient04136/study1_negative/image1.png\")\n",
    "print(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for oxray in otherxray:\n",
    "    XNROM = oxray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:xray]",
   "language": "python",
   "name": "conda-env-xray-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
